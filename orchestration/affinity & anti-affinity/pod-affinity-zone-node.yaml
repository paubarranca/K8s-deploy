# The affinity on this pod defines one pod affinity rule and one pod anti-affinity rule. In this example, the podAffinity is 
# requiredDuringSchedulingIgnoredDuringExecution while the podAntiAffinity is preferredDuringSchedulingIgnoredDuringExecution. 
# The pod affinity rule says that the pod can be scheduled onto a node only if that node is in the same zone as at least one 
# already-running pod that has a label with key “security” and value “S1”. (More precisely, the pod is eligible to run on node N 
# if node N has a label with key failure-domain.beta.kubernetes.io/zone and some value V such that there is at least one node in 
# the cluster with key failure-domain.beta.kubernetes.io/zone and value V that is running a pod that has a label with key “security” 
# and value “S1”.) The pod anti-affinity rule says that the pod prefers not to be scheduled onto a node if that node is already 
# running a pod with label having key “security” and value “S2”. (If the topologyKey were failure-domain.beta.kubernetes.io/zone 
# then it would mean that the pod cannot be scheduled onto a node if that node is in the same zone as a pod with label having key “security” and value “S2”.)

# Source: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#an-example-of-a-pod-that-uses-pod-affinity
apiVersion: v1
kind: Pod
metadata:
  name: with-pod-affinity
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: security
            operator: In
            values:
            - S1
        topologyKey: failure-domain.beta.kubernetes.io/zone
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: security
              operator: In
              values:
              - S2
          topologyKey: failure-domain.beta.kubernetes.io/zone
  containers:
  - name: with-pod-affinity
    image: k8s.gcr.io/pause:2.0
    resources:
      limits:
        memory: "128Mi"
        cpu: "100M"